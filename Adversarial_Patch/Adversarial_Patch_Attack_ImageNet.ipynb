{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adversarial_Patch_Attack.ipynb",
      "provenance": [],
      "mount_file_id": "1J7-Ue8dCrET_hN8bawh_P7NioiaOsEY7",
      "authorship_tag": "ABX9TyMr9Nfvcmew6TQrmtFiRiWc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fef984110b2340719856492f24d5e1a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1b7e23863dd46da8cae7a674f5b598d",
              "IPY_MODEL_33ba24256f4542bd83cc05907252ae65",
              "IPY_MODEL_35aead74a9d54fc094771b73c94a50a0"
            ],
            "layout": "IPY_MODEL_ce1bb17aea77415b9d6e378e0c16ad8e"
          }
        },
        "f1b7e23863dd46da8cae7a674f5b598d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a12ea2c07031498fbaf7d6a8b89a4909",
            "placeholder": "​",
            "style": "IPY_MODEL_089ba16ea0e14f989e111b2f39095742",
            "value": "100%"
          }
        },
        "33ba24256f4542bd83cc05907252ae65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00c56edf091f4234b49c681aa4a311b9",
            "max": 102530333,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4f1b05e432a45f397582b45f41fc6bb",
            "value": 102530333
          }
        },
        "35aead74a9d54fc094771b73c94a50a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_427f726bf4c74ab5a6353bb790f6a0a6",
            "placeholder": "​",
            "style": "IPY_MODEL_06801db20b144100813bc203a257f8bc",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 234MB/s]"
          }
        },
        "ce1bb17aea77415b9d6e378e0c16ad8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a12ea2c07031498fbaf7d6a8b89a4909": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "089ba16ea0e14f989e111b2f39095742": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00c56edf091f4234b49c681aa4a311b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4f1b05e432a45f397582b45f41fc6bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "427f726bf4c74ab5a6353bb790f6a0a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06801db20b144100813bc203a257f8bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JJungEEun/Adversarial_AI_attack/blob/main/Adversarial_Patch/Adversarial_Patch_Attack_ImageNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[코드 구현] Adversarial_Patch_Attack**\n",
        "\n",
        "- 작성자: 정은\n",
        "- 논문 제목: [Adversarial Patch[(https://arxiv.org/pdf/1712.09665.pdf)\n",
        "- 학습 데이터셋:\n",
        "- ImageNet에서 Pytorch의 Adversarial Patch 구현\n",
        "- Reference\n",
        "  + https://github.com/A-LinCui/Adversarial_Patch_Attack\n",
        "  + https://github.com/jhayes14/adversarial-patch\n"
      ],
      "metadata": {
        "id": "LWBgYKxAjDpO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 01. Make Patch"
      ],
      "metadata": {
        "id": "fBNzSznalOIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adversarial Patch: patch_utils\n",
        "# utils for patch initialization and mask generation\n",
        "# Created by Junbo Zhao 2020/3/19\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import math\n",
        "from scipy.ndimage.interpolation import rotate\n",
        "\n",
        "\n",
        "# Initialize the patch\n",
        "def patch_initialization(patch_type='rectangle', image_size=(3, 224, 224), noise_percentage=0.03):\n",
        "    if patch_type == 'rectangle':\n",
        "        mask_length = int((noise_percentage * image_size[1] * image_size[2])**0.5)\n",
        "        patch = np.random.rand(image_size[0], mask_length, mask_length)\n",
        "\n",
        "    if patch_type == 'circle':\n",
        "        radius = int(math.sqrt(noise_percentage * image_size[1] * image_size[1] /math.pi))\n",
        "        patch = np.zeros((1,3, radius*2, radius*2))\n",
        "        for i in range(3):\n",
        "          a = np.zeros((radius*2, radius*2))    \n",
        "          cx, cy = radius, radius # The center of circle \n",
        "          y, x = np.ogrid[-radius: radius, -radius: radius]\n",
        "          index = x**2 + y**2 <= radius**2\n",
        "          a[cy-radius:cy+radius, cx-radius:cx+radius][index] = np.random.rand()\n",
        "          idx = np.flatnonzero((a == 0).all((1)))\n",
        "          a = np.delete(a, idx, axis=0)\n",
        "          patch[0][i] = np.delete(a, idx, axis=1)\n",
        "    return patch\n",
        "\n",
        "\n",
        "# Generate the mask and apply the patch\n",
        "def mask_generation(mask_type='rectangle', patch=None, image_size=(3, 224, 224)):\n",
        "    applied_patch = np.zeros(image_size)\n",
        "    if mask_type == 'rectangle':\n",
        "        # patch rotation\n",
        "        rotation_angle = np.random.choice(4)\n",
        "        for i in range(patch.shape[0]):\n",
        "            patch[i] = np.rot90(patch[i], rotation_angle)  # The actual rotation angle is rotation_angle * 90\n",
        "        # patch location\n",
        "        x_location, y_location = np.random.randint(low=0, high=image_size[1]-patch.shape[1]), np.random.randint(low=0, high=image_size[2]-patch.shape[2])\n",
        "        for i in range(patch.shape[0]):\n",
        "            applied_patch[:, x_location:x_location + patch.shape[1], y_location:y_location + patch.shape[2]] = patch\n",
        "\n",
        "    if mask_type == 'circle':\n",
        "        for i in range(applied_patch.shape[0]):\n",
        "          rotation_angle = np.random.choice(360)\n",
        "          for j in range(patch.shpae[0]):\n",
        "            patch[i][j] = rotate(patch[i][j], rotation_angle)\n",
        "          \n",
        "          x_location, y_location =  np.random.randint(low=0, high=image_size[1]-patch.shape[1]), np.random.randint(low=0, high=image_size[2]-patch.shape[2])\n",
        "          for i in range(patch.shape[0]):\n",
        "            applied_patch[:, x_location:x_location + patch.shape[1], y_location:y_location + patch.shape[2]] = patch\n",
        "\n",
        "      \n",
        "    mask = applied_patch.copy()\n",
        "    mask[mask != 0] = 1.0\n",
        "\n",
        "    return applied_patch, mask, x_location, y_location\n",
        "\n",
        "# Test the patch on dataset\n",
        "def test_patch(patch_type, target, patch, test_loader, model):\n",
        "    model.eval()\n",
        "    test_total, test_actual_total, test_success = 0, 0, 0\n",
        "    for (image, label) in test_loader:\n",
        "        test_total += label.shape[0]\n",
        "        assert image.shape[0] == 1, 'Only one picture should be loaded each time.'\n",
        "        image = image.cuda()\n",
        "        label = label.cuda()\n",
        "        output = model(image)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        if predicted[0] != label and predicted[0].data.cpu().numpy() != target:\n",
        "            test_actual_total += 1\n",
        "            applied_patch, mask, x_location, y_location = mask_generation(patch_type, patch, image_size=(3, 224, 224))\n",
        "            applied_patch = torch.from_numpy(applied_patch)\n",
        "            mask = torch.from_numpy(mask)\n",
        "            perturbated_image = torch.mul(mask.type(torch.FloatTensor), applied_patch.type(torch.FloatTensor)) + torch.mul((1 - mask.type(torch.FloatTensor)), image.type(torch.FloatTensor))\n",
        "            perturbated_image = perturbated_image.cuda()\n",
        "            output = model(perturbated_image)\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            if predicted[0].data.cpu().numpy() == target:\n",
        "                test_success += 1\n",
        "    return test_success / test_actual_total"
      ],
      "metadata": {
        "id": "lJUzEDNQTfBu"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the patch\n",
        "patch = patch_initialization(args.patch_type, image_size=(3, 224, 224), noise_percentage=args.noise_percentage)\n",
        "print('The shape of the patch is', patch.shape)\n",
        "\n",
        "\n",
        "applied_patch, mask, x_location, y_location = mask_generation(args.patch_type, patch, image_size=(3, 224, 224))\n",
        "print(applied_patch.shape, mask.shape, x_location, y_location)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TsWaTrqyTc0",
        "outputId": "849d03ca-57e0-43d1-c73a-687737fc1ab7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the patch is (3, 70, 70)\n",
            "(3, 224, 224) (3, 224, 224) 109 112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the patch\n",
        "patch = patch_initialization('circle', image_size=(3, 224, 224), noise_percentage=args.noise_percentage)\n",
        "print('The shape of the patch is', patch.shape)\n",
        "\n",
        "\n",
        "applied_patch, mask, x_location, y_location = mask_generation('circle', patch, image_size=(3, 224, 224))\n",
        "print(applied_patch.shape, mask.shape, x_location, y_location)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "hd515pMlkpIM",
        "outputId": "c9c3e454-3e99-496f-dc26-5f2fde6d3e34"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the patch is (1, 3, 78, 78)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-106547c9baba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mapplied_patch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'circle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied_patch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-583497e9bd1b>\u001b[0m in \u001b[0;36mmask_generation\u001b[0;34m(mask_type, patch, image_size)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied_patch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m           \u001b[0mrotation_angle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m360\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshpae\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mpatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotation_angle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'shpae'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 02. Load Data"
      ],
      "metadata": {
        "id": "3cJBxyZCnvUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adversarial Patch: utils\n",
        "# Utils in need to generate the patch and test on the dataset.\n",
        "\n",
        "import numpy as np\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "metadata": {
        "id": "JytMJK1d8Ye4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset 불러오기\n",
        "# ImageNet이 너무 커 랜덤하게 데이터 추출\n",
        "def dataloader(train_size, test_size, data_dir, batch_size, num_workers, total_num=50000):\n",
        "    # ImageFolder -> transfrom -> DataLoader\n",
        "\n",
        "    #ImageFolder의 인자: transform (이미지를 변형)\n",
        "    # Shift, Rotate, 형변환 등을 할때 사용된다.\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(), #좌우반전\n",
        "        transforms.ToTensor(), #numpy -> Tensor\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
        "    ])\n",
        "\n",
        "    test_transforms = transforms.Compose([\n",
        "        transforms.Resize(size=(32,32)), #이미지 크기 강제 조정\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    # index = np.arange(total_num)\n",
        "    # np.random.shuffle(index)\n",
        "    # train_index = index[:train_size]\n",
        "    # test_index = index[train_size: (train_size + test_size)]\n",
        "\n",
        "    # ImageFolder 객체는 root_dir, transform등을 인자를 받을 수 있으며, root_dir에는 최상위 경로를 적어주면 된다.\n",
        "    # train_dataset = torchvision.datasets.ImageFolder(root=data_dir, transform=train_transforms)\n",
        "    # test_dataset = torchvision.datasets.ImageFolder(root=data_dir, transform=test_transforms)\n",
        "\n",
        "    # train_dataset = torchvision.datasets.CIFAR10(root=args.data_dir, train=True, download=True, transform=train_transforms)\n",
        "    # test_dataset = torchvision.datasets.CIFAR10(root=args.data_dir, train=False, download=True, transform=test_transforms)\n",
        "\n",
        "    training_dataset = torchvision.datasets.CIFAR10(root=args.data_dir, train=True, download=True, transform=transformer)\n",
        "    validation_dataset =  torchvision.datasets.CIFAR10(root=args.data_dir, train=False, download=True, transform=transformer)\n",
        "\n",
        "    # print(\"train_dataset\", train_dataset.class_to_idx)\n",
        "    # print(\"test_dataset\", test_dataset.class_to_idx)\n",
        "\n",
        "\n",
        "    # DataLoader: ImageFolder 객체를 활용해 인스턴스를 생성한 후, 하나씩 데이터를 가지고오는 작업 수행\n",
        "    # DataLoader 클래스는 ImageFolder로부터 생성된 인스턴스를 인자로 받아 Load하는 기능을 가지고 있다.\n",
        "\n",
        "    training_loader = torch.utils.data.DataLoader(dataset=training_dataset,batch_size=1, num_workers=args.num_workers,shuffle=True)\n",
        "    validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=1, num_workers=args.num_workers,shuffle=False)\n",
        "\n",
        "    # train_loader = DataLoader(dataset=train_dataset, batch_size=100, num_workers=num_workers, pin_memory=True, shuffle=False) \n",
        "    # test_loader = DataLoader(dataset=test_dataset, batch_size=100,  num_workers=num_workers, pin_memory=True, shuffle=False)\n",
        "    # batch: 반복문 돌 때 몇개의 이미지를 가져올지\n",
        "    # sampler: 데이터 불균형 관련\n",
        "    # num_worker: I/O 작업 시 사용할 CPU의 수\n",
        "    # suffle: 이미지 랜덤하게 섞을 지\n",
        "\n",
        "    return training_loader, validation_loader\n"
      ],
      "metadata": {
        "id": "E7sOsG9Z8Rbk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model on clean dataset\n",
        "def test(model, dataloader):\n",
        "    model.eval()\n",
        "    correct, total, loss = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, labels) in enumerate(dataloader):\n",
        "          if args.cuda:\n",
        "            images = images.cuda()         \n",
        "            labels = labels.cuda()\n",
        "      \n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.shape[0]\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "# Load the log and generate the training line\n",
        "def log_generation(log_dir):\n",
        "    # Load the statistics in the log\n",
        "    epochs, train_rate, test_rate = [], [], []\n",
        "    with open(log_dir, 'r') as f:\n",
        "        reader = csv.reader(f)\n",
        "        flag = 0\n",
        "        for i in reader:\n",
        "            if flag == 0:\n",
        "                flag += 1\n",
        "                continue\n",
        "            else:\n",
        "                epochs.append(int(i[0]))\n",
        "                train_rate.append(float(i[1]))\n",
        "                test_rate.append(float(i[2]))\n",
        "\n",
        "    # Generate the success line\n",
        "    plt.figure(num=0)\n",
        "    plt.plot(epochs, test_rate, label='test_success_rate', linewidth=2, color='r')\n",
        "    plt.plot(epochs, train_rate, label='train_success_rate', linewidth=2, color='b')\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.ylabel(\"success rate\")\n",
        "    plt.xlim(-1, max(epochs) + 1)\n",
        "    plt.ylim(0, 1.0)\n",
        "    plt.title(\"patch attack success rate\")\n",
        "    plt.legend()\n",
        "    plt.savefig(\"training_pictures/patch_attack_success_rate.png\")\n",
        "    plt.close(0)"
      ],
      "metadata": {
        "id": "UZWKxr8WUcU1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 03. Adversarial Patch 공격"
      ],
      "metadata": {
        "id": "Tswk1VBK8fdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adversarial Patch Attack\n",
        "\n",
        "\"\"\"\n",
        "Reference:\n",
        "[1] Tom B. Brown, Dandelion Mané, Aurko Roy, Martín Abadi, Justin Gilmer\n",
        "    Adversarial Patch. arXiv:1712.09665\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "\n",
        "import argparse\n",
        "import csv\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import easydict\n",
        "# EasyDict: dict 값에 액세스 할 수 있음(재귀적으로) \n",
        " \n",
        "args = easydict.EasyDict({\n",
        "        \"batch_size\": 1,\n",
        "        \"num_workers\": 0,\n",
        "        \"train_size\": 2000,\n",
        "        \"test_size\": 2000,\n",
        "        \"noise_percentage\": 0.1,\n",
        "        \"probability_threshold\": 0.9,\n",
        "        \"patch_type\": \"rectangle\",\n",
        "        \"lr\": 1.0,\n",
        "        \"max_iteration\": 1000,\n",
        "        \"target\": 3,\n",
        "        \"epochs\": 20,\n",
        "        \"data_dir\":\"/content/drive/MyDrive/Colab Notebooks/dataset\" ,\n",
        "        \"GPU\": \"PCI_BUS_ID\",\n",
        "        \"log_dir\": '/content/drive/MyDrive/Colab Notebooks/patch_attack_log.csv',\n",
        "        \"cuda\": 'store_true'\n",
        "})\n"
      ],
      "metadata": {
        "id": "zw3wxm01Vogb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Optimazation"
      ],
      "metadata": {
        "id": "SnAA4UYR8qCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Patch attack via optimization\n",
        "# According to reference [1], one image is attacked each time\n",
        "# Assert: applied patch should be a numpy\n",
        "# Return the final perturbated picture and the applied patch. Their types are both numpy\n",
        "def patch_attack(image, applied_patch, mask, target, probability_threshold, model, lr=1, max_iteration=100):\n",
        "    model.eval()\n",
        "    applied_patch = torch.from_numpy(applied_patch)\n",
        "    mask = torch.from_numpy(mask)\n",
        "    target_probability, count = 0, 0\n",
        "    perturbated_image = torch.mul(mask.type(torch.FloatTensor), applied_patch.type(torch.FloatTensor)) + torch.mul((1 - mask.type(torch.FloatTensor)), image.type(torch.FloatTensor))\n",
        "    while target_probability < probability_threshold and count < max_iteration:\n",
        "        count += 1\n",
        "        # Optimize the patch\n",
        "        perturbated_image = Variable(perturbated_image.data, requires_grad=True)\n",
        "        per_image = perturbated_image\n",
        "        per_image = per_image.cuda()\n",
        "        output = model(per_image)\n",
        "        target_log_softmax = torch.nn.functional.log_softmax(output, dim=1)[0][target]\n",
        "        target_log_softmax.backward()\n",
        "        patch_grad = perturbated_image.grad.clone().cpu()\n",
        "        perturbated_image.grad.data.zero_()\n",
        "        applied_patch = lr * patch_grad + applied_patch.type(torch.FloatTensor)\n",
        "        applied_patch = torch.clamp(applied_patch, min=-3, max=3)\n",
        "        # Test the patch\n",
        "        perturbated_image = torch.mul(mask.type(torch.FloatTensor), applied_patch.type(torch.FloatTensor)) + torch.mul((1-mask.type(torch.FloatTensor)), image.type(torch.FloatTensor))\n",
        "        perturbated_image = torch.clamp(perturbated_image, min=-3, max=3)\n",
        "        perturbated_image = perturbated_image.cuda()\n",
        "        output = model(perturbated_image)\n",
        "        target_probability = torch.nn.functional.softmax(output, dim=1).data[0][target]\n",
        "    perturbated_image = perturbated_image.cpu().numpy()\n",
        "    applied_patch = applied_patch.cpu().numpy()\n",
        "    return perturbated_image, applied_patch"
      ],
      "metadata": {
        "id": "w38RDM6xeYel"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.GPU\n",
        "\n",
        "# Load the model\n",
        "model = models.resnet50(pretrained=True).cuda()\n"
      ],
      "metadata": {
        "id": "EbgWLDQLeqCJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "fef984110b2340719856492f24d5e1a6",
            "f1b7e23863dd46da8cae7a674f5b598d",
            "33ba24256f4542bd83cc05907252ae65",
            "35aead74a9d54fc094771b73c94a50a0",
            "ce1bb17aea77415b9d6e378e0c16ad8e",
            "a12ea2c07031498fbaf7d6a8b89a4909",
            "089ba16ea0e14f989e111b2f39095742",
            "00c56edf091f4234b49c681aa4a311b9",
            "a4f1b05e432a45f397582b45f41fc6bb",
            "427f726bf4c74ab5a6353bb790f6a0a6",
            "06801db20b144100813bc203a257f8bc"
          ]
        },
        "outputId": "d88d8bf8-a11f-4ae4-ef98-686b8afefb35"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fef984110b2340719856492f24d5e1a6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋 불러오기"
      ],
      "metadata": {
        "id": "wrKx76yP8y1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, test_loader = dataloader(args.train_size, args.test_size, args.data_dir, args.batch_size, args.num_workers, 50000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJLB_Ya9ebpO",
        "outputId": "cd82e002-c00f-48a2-f842-f53e3ca33fa4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Error**\n",
        "\n",
        "FileNotFoundError: Found no valid file for the classes 제목없는 폴더 (2). Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp\n",
        "\n",
        "\n",
        "[root_dir의 구조]\n",
        "\n",
        "\n",
        "    | --- cat/\n",
        "    |      |-- 0001.jpg\n",
        "    |      |-- 0002.jpg\n",
        "    |      |-- 0003.jpg\n",
        "    |      |-- ...\n",
        "    |\n",
        "    \n",
        "    | --- dog/\n",
        "    |      |-- 0001.jpg\n",
        "    |      |-- 0002.jpg\n",
        "    |      |-- 0003.jpg\n",
        "    |      |-- ...\n",
        "    |\n",
        "    \n",
        "    | --- rabbit/\n",
        "    |      |--...\n",
        "\n",
        "https://computistics.tistory.com/7"
      ],
      "metadata": {
        "id": "nF54zBvWk3ok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 정확도 검증\n"
      ],
      "metadata": {
        "id": "RP4BRcnLnqsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the accuracy of model on trainset and testset\n",
        "trainset_acc, test_acc = test(model, train_loader), test(model, test_loader)\n",
        "print('Accuracy of the model on clean trainset and testset is {:.3f}% and {:.3f}%'.format(100*trainset_acc, 100*test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iulH86Q9kAwY",
        "outputId": "67869e56-aed1-409f-d5a2-e7950ab27f43"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on clean trainset and testset is 0.046% and 0.080%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Error1**\n",
        "\n",
        "IndexError: Caught IndexError in DataLoader worker process 0.\n",
        "\n",
        "- 아주 세밀한 원인까지는 파악하지 못했으나, torch의 dataloader 객체에 num_workers 인자를 높은 값으로 지정하여 스레드를 할당하는 과정에서 문제가 생긴 것으로 보입니다.\n",
        "\n",
        "[해결 방법]\n",
        "\n",
        "num_workers = 0\n",
        "\n",
        "---\n",
        "\n",
        "**Error2**\n",
        "IndexError: list index out of range\n",
        "\n",
        "- 이유 모르겠음\n",
        "- ImageNet의 부재 ?\n",
        "\n",
        "[해결방법] cifar 데이터로 수정\n",
        "\n",
        "---\n",
        "\n",
        "**Error3**\n",
        "IndexError: index 43274 is out of bounds for axis 0 with size 10000\n"
      ],
      "metadata": {
        "id": "0lDmsNHe9Rvd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### patch"
      ],
      "metadata": {
        "id": "yeprhiyZ9k2c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "패치 초기화"
      ],
      "metadata": {
        "id": "0HkgwLPY9oGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the patch\n",
        "patch = patch_initialization(args.patch_type, image_size=(3, 224, 224), noise_percentage=args.noise_percentage)\n",
        "print('The shape of the patch is', patch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uky2ywelo0r",
        "outputId": "5b02a48e-0d4a-4634-d2a1-9f4eaeebbe00"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the patch is (3, 70, 70)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the patch\n",
        "patch = patch_initialization('circle', image_size=(3, 224, 224), noise_percentage=args.noise_percentage)\n",
        "print('The shape of the patch is', patch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CZpSTBIjjNN",
        "outputId": "e1a5efce-ecab-43bc-f1a3-1e46fed4ee7e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the patch is (1, 3, 78, 78)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(args.log_dir, 'w') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"epoch\", \"train_success\", \"test_success\"])\n",
        "\n",
        "best_patch_epoch, best_patch_success_rate = 0, 0\n",
        "\n",
        "# Generate the patch\n",
        "for epoch in range(args.epochs):\n",
        "    train_total, train_actual_total, train_success = 0, 0, 0\n",
        "    for (image, label) in train_loader:\n",
        "        train_total += label.shape[0]\n",
        "        assert image.shape[0] == 1, \"Only one picture should be loaded each time.\"\n",
        "        image = image.cuda()\n",
        "        label = label.cuda()\n",
        "        output = model(image)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        if predicted[0] != label and predicted[0].data.cpu().numpy() != args.target:\n",
        "             train_actual_total += 1\n",
        "             applied_patch, mask, x_location, y_location = mask_generation(args.patch_type, patch, image_size=(3, 224, 224))\n",
        "             perturbated_image, applied_patch = patch_attack(image, applied_patch, mask, args.target, args.probability_threshold, model, args.lr, args.max_iteration)\n",
        "             perturbated_image = torch.from_numpy(perturbated_image).cuda()\n",
        "             output = model(perturbated_image)\n",
        "             _, predicted = torch.max(output.data, 1)\n",
        "             if predicted[0].data.cpu().numpy() == args.target:\n",
        "                 train_success += 1\n",
        "             patch = applied_patch[0][:, x_location:x_location + patch.shape[1], y_location:y_location + patch.shape[2]]\n",
        "    mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
        "    plt.imshow(np.clip(np.transpose(patch, (1, 2, 0)) * std + mean, 0, 1))\n",
        "    plt.savefig(\"/content/drive/MyDrive/Colab Notebooks/training_pictures/\" + str(epoch) + \" patch.png\")\n",
        "    print(\"Epoch:{} Patch attack success rate on trainset: {:.3f}%\".format(epoch, 100 * train_success / train_actual_total))\n",
        "    train_success_rate = test_patch(args.patch_type, args.target, patch, test_loader, model)\n",
        "    print(\"Epoch:{} Patch attack success rate on trainset: {:.3f}%\".format(epoch, 100 * train_success_rate))\n",
        "    test_success_rate = test_patch(args.patch_type, args.target, patch, test_loader, model)\n",
        "    print(\"Epoch:{} Patch attack success rate on testset: {:.3f}%\".format(epoch, 100 * test_success_rate))\n",
        "\n",
        "    # Record the statistics\n",
        "    with open(args.log_dir, 'a') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([epoch, train_success_rate, test_success_rate])\n",
        "\n",
        "    if test_success_rate > best_patch_success_rate:\n",
        "        best_patch_success_rate = test_success_rate\n",
        "        best_patch_epoch = epoch\n",
        "        plt.imshow(np.clip(np.transpose(patch, (1, 2, 0)) * std + mean, 0, 1))\n",
        "        plt.savefig(\"/content/drive/MyDrive/Colab Notebooks/training_pictures/best_patch.png\")\n",
        "\n",
        "    # Load the statistics and generate the line\n",
        "    # log_generation(args.log_dir)\n",
        "\n",
        "print(\"The best patch is found at epoch {} with success rate {}% on testset\".format(best_patch_epoch, 100 * best_patch_success_rate))"
      ],
      "metadata": {
        "id": "IQWBVsWoUgWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cotZG23NChmW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}