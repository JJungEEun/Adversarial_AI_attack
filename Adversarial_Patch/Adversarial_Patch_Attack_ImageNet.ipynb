{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adversarial_Patch_Attack.ipynb",
      "provenance": [],
      "mount_file_id": "1J7-Ue8dCrET_hN8bawh_P7NioiaOsEY7",
      "authorship_tag": "ABX9TyMqKTN9/FEW+I2RpLSRafF5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JJungEEun/Adversarial_AI_attack/blob/main/Adversarial_Patch/Adversarial_Patch_Attack_ImageNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[코드 구현] Adversarial_Patch_Attack**\n",
        "\n",
        "- 작성자: 정은\n",
        "- 논문 제목: [Adversarial Patch[(https://arxiv.org/pdf/1712.09665.pdf)\n",
        "- 학습 데이터셋:\n",
        "- ImageNet에서 Pytorch의 Adversarial Patch 구현\n",
        "- Reference\n",
        "  + https://github.com/A-LinCui/Adversarial_Patch_Attack\n",
        "  + https://github.com/jhayes14/adversarial-patch\n"
      ],
      "metadata": {
        "id": "LWBgYKxAjDpO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 01. Make Patch"
      ],
      "metadata": {
        "id": "fBNzSznalOIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adversarial Patch: patch_utils\n",
        "# utils for patch initialization and mask generation\n",
        "# Created by Junbo Zhao 2020/3/19\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Initialize the patch\n",
        "def patch_initialization(patch_type='rectangle', image_size=(3, 224, 224), noise_percentage=0.03):\n",
        "    if patch_type == 'rectangle':\n",
        "        mask_length = int((noise_percentage * image_size[1] * image_size[2])**0.5)\n",
        "        patch = np.random.rand(image_size[0], mask_length, mask_length)\n",
        "    return patch\n",
        "\n",
        "# Generate the mask and apply the patch\n",
        "def mask_generation(mask_type='rectangle', patch=None, image_size=(3, 224, 224)):\n",
        "    applied_patch = np.zeros(image_size)\n",
        "    if mask_type == 'rectangle':\n",
        "        # patch rotation\n",
        "        rotation_angle = np.random.choice(4)\n",
        "        for i in range(patch.shape[0]):\n",
        "            patch[i] = np.rot90(patch[i], rotation_angle)  # The actual rotation angle is rotation_angle * 90\n",
        "        # patch location\n",
        "        x_location, y_location = np.random.randint(low=0, high=image_size[1]-patch.shape[1]), np.random.randint(low=0, high=image_size[2]-patch.shape[2])\n",
        "        for i in range(patch.shape[0]):\n",
        "            applied_patch[:, x_location:x_location + patch.shape[1], y_location:y_location + patch.shape[2]] = patch\n",
        "    mask = applied_patch.copy()\n",
        "    mask[mask != 0] = 1.0\n",
        "    return applied_patch, mask, x_location, y_location\n",
        "\n",
        "# Test the patch on dataset\n",
        "def test_patch(patch_type, target, patch, test_loader, model):\n",
        "    model.eval()\n",
        "    test_total, test_actual_total, test_success = 0, 0, 0\n",
        "    for (image, label) in test_loader:\n",
        "        test_total += label.shape[0]\n",
        "        assert image.shape[0] == 1, 'Only one picture should be loaded each time.'\n",
        "        image = image.cuda()\n",
        "        label = label.cuda()\n",
        "        output = model(image)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        if predicted[0] != label and predicted[0].data.cpu().numpy() != target:\n",
        "            test_actual_total += 1\n",
        "            applied_patch, mask, x_location, y_location = mask_generation(patch_type, patch, image_size=(3, 224, 224))\n",
        "            applied_patch = torch.from_numpy(applied_patch)\n",
        "            mask = torch.from_numpy(mask)\n",
        "            perturbated_image = torch.mul(mask.type(torch.FloatTensor), applied_patch.type(torch.FloatTensor)) + torch.mul((1 - mask.type(torch.FloatTensor)), image.type(torch.FloatTensor))\n",
        "            perturbated_image = perturbated_image.cuda()\n",
        "            output = model(perturbated_image)\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            if predicted[0].data.cpu().numpy() == target:\n",
        "                test_success += 1\n",
        "    return test_success / test_actual_total"
      ],
      "metadata": {
        "id": "lJUzEDNQTfBu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 02. Load Data"
      ],
      "metadata": {
        "id": "3cJBxyZCnvUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adversarial Patch: utils\n",
        "# Utils in need to generate the patch and test on the dataset.\n",
        "\n",
        "import numpy as np\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "metadata": {
        "id": "JytMJK1d8Ye4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset 불러오기\n",
        "# ImageNet이 너무 커 랜덤하게 데이터 추출\n",
        "def dataloader(train_size, test_size, data_dir, batch_size, num_workers, total_num=50000):\n",
        "    # ImageFolder -> transfrom -> DataLoader\n",
        "\n",
        "    #ImageFolder의 인자: transform (이미지를 변형)\n",
        "    # Shift, Rotate, 형변환 등을 할때 사용된다.\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(), #좌우반전\n",
        "        transforms.ToTensor(), #numpy -> Tensor\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)) \n",
        "    ])\n",
        "\n",
        "    test_transforms = transforms.Compose([\n",
        "        transforms.Resize(size=(224, 224)), #이미지 크기 강제 조정\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "    ])\n",
        "\n",
        "    index = np.arange(total_num)\n",
        "    np.random.shuffle(index)\n",
        "    train_index = index[:train_size]\n",
        "    test_index = index[train_size: (train_size + test_size)]\n",
        "\n",
        "    # ImageFolder 객체는 root_dir, transform등을 인자를 받을 수 있으며, root_dir에는 최상위 경로를 적어주면 된다.\n",
        "    train_dataset = torchvision.datasets.ImageFolder(root=data_dir, transform=train_transforms)\n",
        "    test_dataset = torchvision.datasets.ImageFolder(root=data_dir, transform=test_transforms)\n",
        "\n",
        "    print(\"train_dataset\", train_dataset.class_to_idx)\n",
        "    print(\"test_dataset\", test_dataset.class_to_idx)\n",
        "\n",
        "\n",
        "    # DataLoader: ImageFolder 객체를 활용해 인스턴스를 생성한 후, 하나씩 데이터를 가지고오는 작업 수행\n",
        "    # DataLoader 클래스는 ImageFolder로부터 생성된 인스턴스를 인자로 받아 Load하는 기능을 가지고 있다.\n",
        "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, sampler=SubsetRandomSampler(train_index), num_workers=num_workers, pin_memory=True, shuffle=False) \n",
        "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, sampler=SubsetRandomSampler(test_index), num_workers=num_workers, pin_memory=True, shuffle=False)\n",
        "    # batch: 반복문 돌 때 몇개의 이미지를 가져올지\n",
        "    # sampler: 데이터 불균형 관련\n",
        "    # num_worker: I/O 작업 시 사용할 CPU의 수\n",
        "    # suffle: 이미지 랜덤하게 섞을 지\n",
        "\n",
        "    return train_loader, test_loader\n"
      ],
      "metadata": {
        "id": "E7sOsG9Z8Rbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model on clean dataset\n",
        "def test(model, dataloader):\n",
        "    model.eval()\n",
        "    correct, total, loss = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for (images, labels) in dataloader:\n",
        "            print(images, labels)\n",
        "            images = images.cuda()         \n",
        "            labels = labels.cuda()\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.shape[0]\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "# Load the log and generate the training line\n",
        "def log_generation(log_dir):\n",
        "    # Load the statistics in the log\n",
        "    epochs, train_rate, test_rate = [], [], []\n",
        "    with open(log_dir, 'r') as f:\n",
        "        reader = csv.reader(f)\n",
        "        flag = 0\n",
        "        for i in reader:\n",
        "            if flag == 0:\n",
        "                flag += 1\n",
        "                continue\n",
        "            else:\n",
        "                epochs.append(int(i[0]))\n",
        "                train_rate.append(float(i[1]))\n",
        "                test_rate.append(float(i[2]))\n",
        "\n",
        "    # Generate the success line\n",
        "    plt.figure(num=0)\n",
        "    plt.plot(epochs, test_rate, label='test_success_rate', linewidth=2, color='r')\n",
        "    plt.plot(epochs, train_rate, label='train_success_rate', linewidth=2, color='b')\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.ylabel(\"success rate\")\n",
        "    plt.xlim(-1, max(epochs) + 1)\n",
        "    plt.ylim(0, 1.0)\n",
        "    plt.title(\"patch attack success rate\")\n",
        "    plt.legend()\n",
        "    plt.savefig(\"training_pictures/patch_attack_success_rate.png\")\n",
        "    plt.close(0)"
      ],
      "metadata": {
        "id": "UZWKxr8WUcU1"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 03. Adversarial Patch 공격"
      ],
      "metadata": {
        "id": "Tswk1VBK8fdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adversarial Patch Attack\n",
        "# Created by Junbo Zhao 2020/3/17\n",
        "\n",
        "\"\"\"\n",
        "Reference:\n",
        "[1] Tom B. Brown, Dandelion Mané, Aurko Roy, Martín Abadi, Justin Gilmer\n",
        "    Adversarial Patch. arXiv:1712.09665\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "\n",
        "import argparse\n",
        "import csv\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import easydict\n",
        "# EasyDict: dict 값에 액세스 할 수 있음(재귀적으로) \n",
        " \n",
        "args = easydict.EasyDict({\n",
        "        \"batch_size\": 1,\n",
        "        \"num_workers\": 0,\n",
        "        \"train_size\": 2000,\n",
        "        \"test_size\": 2000,\n",
        "        \"noise_percentage\": 0.1,\n",
        "        \"probability_threshold\": 0.9,\n",
        "        \"patch_type\": \"rectangle\",\n",
        "        \"lr\": 1.0,\n",
        "        \"max_iteration\": 1000,\n",
        "        \"target\": 3,\n",
        "        \"epochs\": 20,\n",
        "        \"data_dir\":\"/content/drive/MyDrive/Colab Notebooks/dataset\" ,\n",
        "        \"GPU\": \"PCI_BUS_ID\",\n",
        "        \"log_dir\": 'patch_attack_log.csv'\n",
        "})\n"
      ],
      "metadata": {
        "id": "zw3wxm01Vogb"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Optimazation"
      ],
      "metadata": {
        "id": "SnAA4UYR8qCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Patch attack via optimization\n",
        "# According to reference [1], one image is attacked each time\n",
        "# Assert: applied patch should be a numpy\n",
        "# Return the final perturbated picture and the applied patch. Their types are both numpy\n",
        "def patch_attack(image, applied_patch, mask, target, probability_threshold, model, lr=1, max_iteration=100):\n",
        "    model.eval()\n",
        "    applied_patch = torch.from_numpy(applied_patch)\n",
        "    mask = torch.from_numpy(mask)\n",
        "    target_probability, count = 0, 0\n",
        "    perturbated_image = torch.mul(mask.type(torch.FloatTensor), applied_patch.type(torch.FloatTensor)) + torch.mul((1 - mask.type(torch.FloatTensor)), image.type(torch.FloatTensor))\n",
        "    while target_probability < probability_threshold and count < max_iteration:\n",
        "        count += 1\n",
        "        # Optimize the patch\n",
        "        perturbated_image = Variable(perturbated_image.data, requires_grad=True)\n",
        "        per_image = perturbated_image\n",
        "        per_image = per_image.cuda()\n",
        "        output = model(per_image)\n",
        "        target_log_softmax = torch.nn.functional.log_softmax(output, dim=1)[0][target]\n",
        "        target_log_softmax.backward()\n",
        "        patch_grad = perturbated_image.grad.clone().cpu()\n",
        "        perturbated_image.grad.data.zero_()\n",
        "        applied_patch = lr * patch_grad + applied_patch.type(torch.FloatTensor)\n",
        "        applied_patch = torch.clamp(applied_patch, min=-3, max=3)\n",
        "        # Test the patch\n",
        "        perturbated_image = torch.mul(mask.type(torch.FloatTensor), applied_patch.type(torch.FloatTensor)) + torch.mul((1-mask.type(torch.FloatTensor)), image.type(torch.FloatTensor))\n",
        "        perturbated_image = torch.clamp(perturbated_image, min=-3, max=3)\n",
        "        perturbated_image = perturbated_image.cuda()\n",
        "        output = model(perturbated_image)\n",
        "        target_probability = torch.nn.functional.softmax(output, dim=1).data[0][target]\n",
        "    perturbated_image = perturbated_image.cpu().numpy()\n",
        "    applied_patch = applied_patch.cpu().numpy()\n",
        "    return perturbated_image, applied_patch"
      ],
      "metadata": {
        "id": "w38RDM6xeYel"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.GPU\n",
        "\n",
        "# Load the model\n",
        "model = models.resnet50(pretrained=True).cuda()\n"
      ],
      "metadata": {
        "id": "EbgWLDQLeqCJ"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋 불러오기"
      ],
      "metadata": {
        "id": "wrKx76yP8y1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, test_loader = dataloader(args.train_size, args.test_size, args.data_dir, args.batch_size, args.num_workers, 50000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJLB_Ya9ebpO",
        "outputId": "329d4522-c0df-4e67-920b-449f34c24caf"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_dataset {'제목없는 폴더1': 0, '제목없는 폴더2': 1}\n",
            "test_dataset {'제목없는 폴더1': 0, '제목없는 폴더2': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Error**\n",
        "\n",
        "FileNotFoundError: Found no valid file for the classes 제목없는 폴더 (2). Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp\n",
        "\n",
        "\n",
        "[root_dir의 구조]\n",
        "\n",
        "\n",
        "    | --- cat/\n",
        "    |      |-- 0001.jpg\n",
        "    |      |-- 0002.jpg\n",
        "    |      |-- 0003.jpg\n",
        "    |      |-- ...\n",
        "    |\n",
        "    \n",
        "    | --- dog/\n",
        "    |      |-- 0001.jpg\n",
        "    |      |-- 0002.jpg\n",
        "    |      |-- 0003.jpg\n",
        "    |      |-- ...\n",
        "    |\n",
        "    \n",
        "    | --- rabbit/\n",
        "    |      |--...\n",
        "\n",
        "https://computistics.tistory.com/7"
      ],
      "metadata": {
        "id": "nF54zBvWk3ok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 정확도 검증\n"
      ],
      "metadata": {
        "id": "RP4BRcnLnqsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the accuracy of model on trainset and testset\n",
        "trainset_acc, test_acc = test(model, train_loader), test(model, test_loader)\n",
        "print('Accuracy of the model on clean trainset and testset is {:.3f}% and {:.3f}%'.format(100*trainset_acc, 100*test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "iulH86Q9kAwY",
        "outputId": "9e0658dc-b686-4a46-9c31-a59251fbf2d7"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-187-4efe7453393a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test the accuracy of model on trainset and testset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainset_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy of the model on clean trainset and testset is {:.3f}% and {:.3f}%'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrainset_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-182-961cff52adf3>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mclass_index\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \"\"\"\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Error1**\n",
        "\n",
        "IndexError: Caught IndexError in DataLoader worker process 0.\n",
        "\n",
        "- 아주 세밀한 원인까지는 파악하지 못했으나, torch의 dataloader 객체에 num_workers 인자를 높은 값으로 지정하여 스레드를 할당하는 과정에서 문제가 생긴 것으로 보입니다.\n",
        "\n",
        "[해결 방법]\n",
        "\n",
        "num_workers = 0\n",
        "\n",
        "---\n",
        "\n",
        "**Error2**\n",
        "IndexError: list index out of range\n",
        "\n",
        "- 이유 모르겠음\n",
        "- ImageNet의 부재 ?\n"
      ],
      "metadata": {
        "id": "0lDmsNHe9Rvd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### patch"
      ],
      "metadata": {
        "id": "yeprhiyZ9k2c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "패치 초기화"
      ],
      "metadata": {
        "id": "0HkgwLPY9oGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the patch\n",
        "patch = patch_initialization(args.patch_type, image_size=(3, 224, 224), noise_percentage=args.noise_percentage)\n",
        "print('The shape of the patch is', patch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uky2ywelo0r",
        "outputId": "0c36e3fb-5119-4bf8-9c43-e52996da5ea4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the patch is (3, 70, 70)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(args.log_dir, 'w') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"epoch\", \"train_success\", \"test_success\"])\n",
        "\n",
        "best_patch_epoch, best_patch_success_rate = 0, 0\n",
        "\n",
        "# Generate the patch\n",
        "for epoch in range(args.epochs):\n",
        "    train_total, train_actual_total, train_success = 0, 0, 0\n",
        "    for (image, label) in train_loader:\n",
        "        train_total += label.shape[0]\n",
        "        assert image.shape[0] == 1, 'Only one picture should be loaded each time.'\n",
        "        image = image.cuda()\n",
        "        label = label.cuda()\n",
        "        output = model(image)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        if predicted[0] != label and predicted[0].data.cpu().numpy() != args.target:\n",
        "             train_actual_total += 1\n",
        "             applied_patch, mask, x_location, y_location = mask_generation(args.patch_type, patch, image_size=(3, 224, 224))\n",
        "             perturbated_image, applied_patch = patch_attack(image, applied_patch, mask, args.target, args.probability_threshold, model, args.lr, args.max_iteration)\n",
        "             perturbated_image = torch.from_numpy(perturbated_image).cuda()\n",
        "             output = model(perturbated_image)\n",
        "             _, predicted = torch.max(output.data, 1)\n",
        "             if predicted[0].data.cpu().numpy() == args.target:\n",
        "                 train_success += 1\n",
        "             patch = applied_patch[0][:, x_location:x_location + patch.shape[1], y_location:y_location + patch.shape[2]]\n",
        "    mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
        "    plt.imshow(np.clip(np.transpose(patch, (1, 2, 0)) * std + mean, 0, 1))\n",
        "    plt.savefig(\"training_pictures/\" + str(epoch) + \" patch.png\")\n",
        "    print(\"Epoch:{} Patch attack success rate on trainset: {:.3f}%\".format(epoch, 100 * train_success / train_actual_total))\n",
        "    train_success_rate = test_patch(args.patch_type, args.target, patch, test_loader, model)\n",
        "    print(\"Epoch:{} Patch attack success rate on trainset: {:.3f}%\".format(epoch, 100 * train_success_rate))\n",
        "    test_success_rate = test_patch(args.patch_type, args.target, patch, test_loader, model)\n",
        "    print(\"Epoch:{} Patch attack success rate on testset: {:.3f}%\".format(epoch, 100 * test_success_rate))\n",
        "\n",
        "    # Record the statistics\n",
        "    with open(args.log_dir, 'a') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([epoch, train_success_rate, test_success_rate])\n",
        "\n",
        "    if test_success_rate > best_patch_success_rate:\n",
        "        best_patch_success_rate = test_success_rate\n",
        "        best_patch_epoch = epoch\n",
        "        plt.imshow(np.clip(np.transpose(patch, (1, 2, 0)) * std + mean, 0, 1))\n",
        "        plt.savefig(\"training_pictures/best_patch.png\")\n",
        "\n",
        "    # Load the statistics and generate the line\n",
        "    log_generation(args.log_dir)\n",
        "\n",
        "print(\"The best patch is found at epoch {} with success rate {}% on testset\".format(best_patch_epoch, 100 * best_patch_success_rate))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "IQWBVsWoUgWq",
        "outputId": "637d636d-89b7-47e3-a48e-bdef8f70184d"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-186-c91ae982e59f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_actual_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_success\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtrain_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Only one picture should be loaded each time.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mclass_index\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \"\"\"\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    }
  ]
}